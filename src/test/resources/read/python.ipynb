{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "python.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1521HiyYO_L-9NSkLe13IqT-DY7EJWH57",
   "authorship_tag": "ABX9TyPz3TO0GBzKW9MhiWBboXjb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test Markdown\n",
    "second row"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!cp \"/content/drive/MyDrive/8. Semester/architectures.py\" /content\n",
    "!cp \"/content/drive/MyDrive/8. Semester/dataloader.py\" /content\n",
    "!cp \"/content/drive/MyDrive/8. Semester/ex4_sample.py\" /content\n",
    "!cp \"/content/drive/MyDrive/8. Semester/utils.py\" /content\n",
    "!cp \"/content/drive/MyDrive/8. Semester/working_config.json\" /content\n",
    "!cp \"/content/drive/MyDrive/8. Semester/training.zip\" /content"
   ],
   "metadata": {
    "id": "_OBn05EE588E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369064772,
     "user_tz": -120,
     "elapsed": 11380,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip /content/training.zip"
   ],
   "metadata": {
    "id": "tnFxXE2W_t5B",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369070972,
     "user_tz": -120,
     "elapsed": 6227,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    },
    "outputId": "f2e76470-69d9-4b64-f82e-6c7b3576761b",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B9_KCjqE3YZ8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369074274,
     "user_tz": -120,
     "elapsed": 3321,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.utils.data\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from architectures import ChallengeCNN\n",
    "from dataloader import AugmentedImages, image_collate_fn, TestDataset, SimpleImageDataset, AugmentedImages\n",
    "from utils import plot, RMSELoss, store_to_drive, restore_from_drive"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn, device: torch.device):\n",
    "    \"\"\"Function for evaluation of a model `model` on the data in `dataloader` on device `device`,\n",
    "    using the specified `loss_fn` loss function\"\"\"\n",
    "    model.eval()\n",
    "    # We will accumulate the mean loss in variable `loss`\n",
    "    loss = 0\n",
    "    with torch.no_grad():  # We do not need gradients for evaluation\n",
    "        # Loop over all samples in `dataloader`\n",
    "        for data in tqdm(dataloader, desc=\"scoring\", position=0):\n",
    "            # Get a sample and move inputs and targets to device\n",
    "            images, inputs, known, means, stds, file_names = data\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            known = known.to(device)\n",
    "            means = means.to(device)\n",
    "            stds = stds.to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Get outputs of the specified model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = (outputs.permute(2, 3, 0, 1) * stds + means).permute(2, 3, 0, 1)\n",
    "            # outputs = (outputs.permute(1, 2, 3, 0) * stds + means).permute(3, 0, 1, 2)\n",
    "\n",
    "            # mask out known values\n",
    "            masked_outputs = torch.where(known == 0, outputs, images) * 255\n",
    "            images *= 255\n",
    "\n",
    "            masked_outputs.int()\n",
    "            images.int()\n",
    "            # Here we could clamp the outputs to the minimum and maximum values of inputs for better performance\n",
    "\n",
    "            # Add the current loss, which is the mean loss over all minibatch samples\n",
    "            # (unless explicitly otherwise specified when creating the loss function!)\n",
    "            loss += loss_fn(masked_outputs, images).item()\n",
    "    # Get final mean loss by dividing by the number of minibatch iterations (which\n",
    "    # we summed up in the above loop)\n",
    "    loss /= len(dataloader)\n",
    "    model.train()\n",
    "    print(f\"loss: {loss}\")\n",
    "    return loss"
   ],
   "metadata": {
    "id": "8747kaYK3dsj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369074277,
     "user_tz": -120,
     "elapsed": 27,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main(results_path,\n",
    "         training_path: str,\n",
    "         network_config: dict,\n",
    "         learningrate: int = 1e-3,\n",
    "         weight_decay: float = 1e-5,\n",
    "         n_updates: int = int(1e5),\n",
    "         device: torch.device = torch.device(\"cuda:0\"),\n",
    "         num_workers: int = 0,\n",
    "         batch_size: int = 2):\n",
    "    \"\"\"Main function that takes hyperparameters and performs training and evaluation of model\"\"\"\n",
    "\n",
    "    results_path = f\"{results_path}{training_path.replace('training', '')}_ks{network_config['kernel_size']}_l{network_config['n_hidden_layers']}\"\n",
    "\n",
    "    # Prepare a path to plot to\n",
    "    plotpath = os.path.join(results_path, 'plots')\n",
    "    os.makedirs(plotpath, exist_ok=True)\n",
    "\n",
    "    # Load or dataset\n",
    "    image_dataset = SimpleImageDataset(data_folder=training_path)\n",
    "\n",
    "    # 1. Decide which samples you want to use in your training-, validation- or test sets.\n",
    "    # Split dataset into training, validation, and test set randomly\n",
    "    training_set = torch.utils.data.Subset(image_dataset, indices=np.arange(int(len(image_dataset) * (3 / 5))))\n",
    "    validation_set = torch.utils.data.Subset(image_dataset, indices=np.arange(int(len(image_dataset) * (3 / 5)),\n",
    "                                                                              int(len(image_dataset) * (4 / 5))))\n",
    "    test_set = torch.utils.data.Subset(image_dataset,\n",
    "                                       indices=np.arange(int(len(image_dataset) * (4 / 5)), len(image_dataset)))\n",
    "\n",
    "    # Create datasets and dataloaders without augmentation (for evaluation)\n",
    "    train_loader = DataLoader(AugmentedImages(training_set),\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=num_workers,\n",
    "                              collate_fn=image_collate_fn)\n",
    "    val_loader = DataLoader(AugmentedImages(validation_set),\n",
    "                            batch_size=1, shuffle=False,\n",
    "                            num_workers=num_workers,\n",
    "                            collate_fn=image_collate_fn)\n",
    "    test_loader = DataLoader(AugmentedImages(test_set),\n",
    "                             batch_size=1, shuffle=False,\n",
    "                             num_workers=num_workers,\n",
    "                             collate_fn=image_collate_fn)\n",
    "\n",
    "    # Create datasets and dataloaders with rotated targets with augmentation (for training)\n",
    "    transform_chain = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip()])\n",
    "\n",
    "    training_set_augmented = AugmentedImages(dataset=training_set, transform_chain=transform_chain)\n",
    "    train_loader_augmented = DataLoader(training_set_augmented, batch_size=batch_size, shuffle=True,\n",
    "                                        num_workers=num_workers,\n",
    "                                        collate_fn=image_collate_fn)\n",
    "\n",
    "    # Define a tensorboard summary writer that writes to directory \"results_path/tensorboard\"\n",
    "    writer = SummaryWriter(log_dir=os.path.join(results_path, 'tensorboard'))\n",
    "\n",
    "    # Create Network\n",
    "    net = ChallengeCNN(**network_config)\n",
    "    net.to(device)\n",
    "\n",
    "    # Get mse loss function\n",
    "    mse = RMSELoss\n",
    "\n",
    "    # Get adam optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learningrate, weight_decay=weight_decay)\n",
    "\n",
    "    interval = 1000\n",
    "    print_stats_at = 100  # print status to tensorboard every x updates\n",
    "    plot_at = interval  # plot every x updates\n",
    "    validate_at = interval  # evaluate model on validation set and check for new best model every x updates\n",
    "\n",
    "    # Save initial model as \"best\" model (will be overwritten later)\n",
    "    best_model_file = os.path.join(results_path, f\"best_model.pt\")\n",
    "    last_model_file = os.path.join(results_path, f\"last_model.pt\")\n",
    "    progress_file = os.path.join(results_path, f\"progress.txt\")\n",
    "\n",
    "    if TRAIN:  # Train until n_updates updates have been reached\n",
    "        update_progress_bar = tqdm(total=n_updates, desc=f\"loss: {np.nan:7.5f}\", position=0)\n",
    "\n",
    "        if TRAIN_CONTINUE:\n",
    "            #restore_from_drive(results_path)\n",
    "            with open(progress_file, 'r') as f:\n",
    "                x = f.read().split('\\n')\n",
    "                update = int(x[0])\n",
    "                best_validation_loss = float(x[1])\n",
    "                f.close()\n",
    "\n",
    "            update_progress_bar.n = update\n",
    "            update_progress_bar.refresh()\n",
    "            net = torch.load(last_model_file)\n",
    "        else:\n",
    "            update = 0  # current update counter\n",
    "            best_validation_loss = np.inf  # best validation loss so far\n",
    "            torch.save(net, best_model_file)\n",
    "\n",
    "        while update < n_updates:\n",
    "            for data in train_loader_augmented:\n",
    "                # Get next samples\n",
    "                images, inputs, known, means, stds, ids = data\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                known = known.to(device)\n",
    "                means = means.to(device)\n",
    "                stds = stds.to(device)\n",
    "                images = images.to(device)\n",
    "\n",
    "                # Reset gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Get outputs for network\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                outputs = (outputs.permute(2, 3, 0, 1) * stds + means).permute(2, 3, 0, 1)\n",
    "\n",
    "                # Calculate loss, do backward pass, and update weights\n",
    "                # mask out known values\n",
    "                masked_outputs = torch.where(known == 0.0, outputs, images) * 255\n",
    "                images *= 255\n",
    "\n",
    "                loss = mse(masked_outputs, images)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print current status and score\n",
    "                if (update + 1) % print_stats_at == 0:\n",
    "                    writer.add_scalar(tag=\"training/loss\", scalar_value=loss.cpu(), global_step=update)\n",
    "\n",
    "                # Plot output\n",
    "                if PLOT_TRAINING and (update + 1) % plot_at == 0:\n",
    "                    plot(inputs.detach().cpu().numpy(), images.detach().cpu().numpy(),\n",
    "                         masked_outputs.detach().cpu().numpy(),\n",
    "                         plotpath, update)\n",
    "\n",
    "                # Evaluate model on validation set\n",
    "                if (update + 1) % validate_at == 0:\n",
    "                    val_loss = evaluate_model(net, dataloader=val_loader, loss_fn=mse, device=device)\n",
    "                    writer.add_scalar(tag=\"validation/loss\", scalar_value=val_loss, global_step=update)\n",
    "                    # Add weights and gradients as arrays to tensorboard\n",
    "                    for i, (name, param) in enumerate(net.named_parameters()):\n",
    "                        writer.add_histogram(tag=f\"validation/param_{i} ({name})\", values=param.cpu(),\n",
    "                                             global_step=update)\n",
    "                        writer.add_histogram(tag=f\"validation/gradients_{i} ({name})\", values=param.grad.cpu(),\n",
    "                                             global_step=update)\n",
    "                    # Save best model for early stopping\n",
    "                    if val_loss < best_validation_loss:\n",
    "                        best_validation_loss = val_loss\n",
    "                        torch.save(net, best_model_file)\n",
    "\n",
    "                    torch.save(net, last_model_file)\n",
    "                    with open(progress_file, 'w') as f:\n",
    "                        f.write(str(update + 1))\n",
    "                        f.write('\\n')\n",
    "                        f.write(str(best_validation_loss))\n",
    "                        f.close()\n",
    "\n",
    "                    #store_to_drive(results_path)\n",
    "\n",
    "                update_progress_bar.set_description(f\"loss: {loss:7.5f}\", refresh=True)\n",
    "                update_progress_bar.update()\n",
    "\n",
    "                # Increment update counter, exit if maximum number of updates is reached\n",
    "                # Here, we could apply some early stopping heuristic and also exit if its\n",
    "                # stopping criterion is met\n",
    "                update += 1\n",
    "                if update >= n_updates:\n",
    "                    break\n",
    "\n",
    "        update_progress_bar.close()\n",
    "        writer.close()\n",
    "        print(\"\\nFinished Training!\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        writer.close()\n",
    "        print(\"\\nNo Training!\")\n",
    "\n",
    "    if EVALUATE:\n",
    "        # Load best model and compute score on test set\n",
    "        print(f\"Computing scores for best model\")\n",
    "        net = torch.load(best_model_file)\n",
    "        train_loss = evaluate_model(net, dataloader=train_loader, loss_fn=mse, device=device)\n",
    "        val_loss = evaluate_model(net, dataloader=val_loader, loss_fn=mse, device=device)\n",
    "        test_loss = evaluate_model(net, dataloader=test_loader, loss_fn=mse, device=device)\n",
    "\n",
    "        print(f\"Scores:\")\n",
    "        print(f\"  training loss: {train_loss}\")\n",
    "        print(f\"validation loss: {val_loss}\")\n",
    "        print(f\"      test loss: {test_loss}\")\n",
    "\n",
    "        # Write result to file\n",
    "        with open(os.path.join(results_path, f\"results.txt\"), \"w\") as rf:\n",
    "            print(f\"Scores:\", file=rf)\n",
    "            print(f\"  training loss: {train_loss}\", file=rf)\n",
    "            print(f\"validation loss: {val_loss}\", file=rf)\n",
    "            print(f\"      test loss: {test_loss}\", file=rf)\n",
    "\n",
    "    if PREDICT:\n",
    "        print(f\"Computing pixels for challenge\")\n",
    "        net = torch.load(best_model_file)\n",
    "        challenge_test_dataset = TestDataset(\"test\")\n",
    "        challenge_plotpath = os.path.join(results_path, 'predictions')\n",
    "        os.makedirs(challenge_plotpath, exist_ok=True)\n",
    "        challenge_test_loader = DataLoader(challenge_test_dataset, shuffle=False, batch_size=1,\n",
    "                                           collate_fn=image_collate_fn)\n",
    "        # collate_fn=image_collate_fn)\n",
    "        predict_unknown(net, dataloader=challenge_test_loader, results_path=results_path, plot_path=challenge_plotpath,\n",
    "                        device=device)"
   ],
   "metadata": {
    "id": "DuXsfe6U8LOV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369093282,
     "user_tz": -120,
     "elapsed": 1067,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# enable training will create a new model and overwrite any existing\n",
    "TRAIN = True\n",
    "TRAIN_CONTINUE = True\n",
    "\n",
    "EVALUATE = True\n",
    "PREDICT = False\n",
    "\n",
    "PLOT_TRAINING = False\n",
    "PLOT_PREDICTIONS = False\n"
   ],
   "metadata": {
    "id": "VMF-_6TBZ_3V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369170472,
     "user_tz": -120,
     "elapsed": 752,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"working_config.json\") as cf:\n",
    "    config = json.load(cf)\n",
    "\n",
    "main(**config)"
   ],
   "metadata": {
    "id": "mHKEj9eu3or1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1657372387563,
     "user_tz": -120,
     "elapsed": 3202881,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    },
    "outputId": "64858c67-0986-4ada-c340-017b3b25cdf0"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "scoring: 100%|██████████| 5882/5882 [00:53<00:00, 109.51it/s]\n",
      "loss: 16.52635:  20%|██        | 4000/20000 [23:01<77:32:21, 17.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 15.700774341446735\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "scoring: 100%|██████████| 5882/5882 [00:55<00:00, 106.65it/s]\n",
      "loss: 15.99991:  25%|██▌       | 5000/20000 [45:48<74:24:24, 17.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 15.71925485853596\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loss: 16.89904:  27%|██▋       | 5333/20000 [53:02<5:24:41,  1.33s/it]"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-8a81112b12bd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mconfig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-6-f1f8d442a8c5>\u001B[0m in \u001B[0;36mmain\u001B[0;34m(results_path, training_path, network_config, learningrate, weight_decay, n_updates, device, num_workers, batch_size)\u001B[0m\n\u001B[1;32m    155\u001B[0m                     \u001B[0;31m#store_to_drive(results_path)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m                 \u001B[0mupdate_progress_bar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_description\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"loss: {loss:7.5f}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrefresh\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m                 \u001B[0mupdate_progress_bar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001B[0m in \u001B[0;36m__format__\u001B[0;34m(self, format_spec)\u001B[0m\n\u001B[1;32m    625\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__format__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    626\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 627\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__format__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mformat_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    628\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__format__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    629\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "id": "uJzoKnIWbezJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# store to drive\n",
    "!cp -r /content/results_ks3_l6 \"/content/drive/MyDrive/8. Semester/results_ks3_l6_nopad\""
   ],
   "metadata": {
    "id": "OSrRApOsCXmM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657372398394,
     "user_tz": -120,
     "elapsed": 532,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# restore from drive\n",
    "!cp -r \"/content/drive/MyDrive/8. Semester/results_ks3_l6_nopad\" /content/results_ks3_l6"
   ],
   "metadata": {
    "id": "XdFIdQMuNoTB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657369053406,
     "user_tz": -120,
     "elapsed": 9135,
     "user": {
      "displayName": "Matthias Preuner",
      "userId": "17553543681398641464"
     }
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -rf /content/results_ks3_l6"
   ],
   "metadata": {
    "id": "Q2L7oGhBOcVo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def store_to_drive(results_path):\n",
    "    drive_path = os.path.join( \"/content/drive/MyDrive/8. Semester/\", results_path)\n",
    "    shutil.copytree(os.path.join(\"/content\", results_path), drive_path)\n",
    "\n",
    "def restore_from_drive(results_path):\n",
    "    drive_path = os.path.join( \"/content/drive/MyDrive/8. Semester/\", results_path)\n",
    "    shutil.copytree(drive_path, os.path.join(\"/content\", results_path))\n"
   ],
   "metadata": {
    "id": "ilGEHdO099cU"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
